# Algorithm

<https://leetcode.com/problems/merge-sorted-array/description/>



```python3
class Solution:
    def merge(self, nums1: List[int], m: int, nums2: List[int], n: int) -> None:
        """
        Do not return anything, modify nums1 in-place instead.
        """
        # nums1[m:] = nums2[:]
        # nums1.sort()

        if m == 0:
            for i in range(n):
                nums1[i] = nums2[i]
            return
        
        if n == 0:
            return 
               
        i = j = 0
        while j<n and i<m+n:
            if nums2[j]<=nums1[i]:
                nums1[i+1:]=nums1[i:-1]
                nums1[i]=nums2[j]
                j+=1
            elif i>=(j+m):
                nums1[i:]=nums2[j:]
                break
            i+=1
```



# Review

<https://www.artima.com/weblogs/viewpost.jsp?thread=147358>

语言的设计不应该仅仅是为了解决难题，还有某些“特别的”，这也是我一直喜欢python的原因，很多人说python效率低，也替代不了什么工业级的解决方案，但是在我内心而言，根本不需要，每个语言都有其独特的艺术魅力反而更加让人着迷。也许不久之后我会尝试go，或者其他的，但是我会一直保持着"Pythonicity", 简单明了





# Tips && Share

本周刚好有个工作需要用到异步，就临时操刀弄了下。 python3倒是有asyncio模块可以直接使用，不过二次开发的开源版本使用的是python2，而且内嵌了有celery，就想着不改变原有框架继续沿用。就写了下，主体还是比较简单的，也实现了，中间确实出现了很多漏子，几近放弃，第一是不知道为什么在测试环境celery就是不执行我的task，但是同样的配置我在其他环境写了一个demo，完全没有问题，问题直到现在依旧不知道是什么情况，但是时间有限果断放弃，重新部署了一套测试环境，问题解决，第二，也是困扰最久的问题，就是异步的task中执行的ansible无法得到返回，然后谷歌用了的方法很笃定，都是要在运行我引入的supervisor之前声明一个环境变量，但是不知道为什么我的就是不生效，随后采取了修改参数 -O OPTIMIZATION，不知道为什么当时也没生效，最后清掉所有变动重新运行却好了，其实中间还是celery有些缓存的结果影响了判断。

从这次事中收获了几点：

1. 一些调试的技巧，倒不是什么工具的使用，而是思维，想法。
2.  心态问题，遇到问题就慢慢一个个排除找到根本，不知道为什么脑海中有解决方案，不知道为什么就是不行动，习惯先思考完再动手，其实有些灵感是在动手中慢慢摸寻的
3. 念念不忘必有回响



下面具体的介绍下这个celery模块和使用中的注意点：

首先，celery是一个基于python的开源分布式调度系统，模块架构也比较简洁，分别如下几个模块：

**任务生产者 (task producer)**

任务生产者 (task producer) 负责产生计算任务，交给任务队列去处理。在 Celery 里，一段独立的 Python 代码、一段嵌入在 Django Web 服务里的一段请求处理逻辑，只要是调用了 Celery 提供的 API，产生任务并交给任务队列处理的，我们都可以称之为任务生产者。

**任务调度器 (celery beat)**

Celery beat 是一个任务调度器，它以独立进程的形式存在。Celery beat 进程会读取配置文件的内容，周期性地将执行任务的请求发送给任务队列。Celery beat 是 Celery 系统自带的任务生产者。系统管理员可以选择关闭或者开启 Celery beat。同时在一个 Celery 系统中，只能存在一个 Celery beat 调度器。

**任务代理 (broker)**

任务代理方负责接受任务生产者发送过来的任务处理消息，存进队列之后再进行调度，分发给任务消费方 (celery worker)。因为任务处理是基于 message(消息) 的，所以我们一般选择 RabbitMQ、Redis 等消息队列或者数据库作为 Celery 的 message broker。

**任务消费方 (celery worker)**

Celery worker 就是执行任务的一方，它负责接收任务处理中间方发来的任务处理请求，完成这些任务，并且返回任务处理的结果。Celery worker 对应的就是操作系统中的一个进程。Celery 支持分布式部署和横向扩展，我们可以在多个节点增加 Celery worker 的数量来增加系统的高可用性。在分布式系统中，我们也可以在不同节点上分配执行不同任务的 Celery worker 来达到模块化的目的。

**结果保存**

Celery 支持任务处理完后将状态信息和结果的保存，以供查询。Celery 内置支持 rpc, Django ORM，Redis，RabbitMQ 等方式来保存任务处理后的状态信息。



具体的使用放在了下面的参考网址上，这里介绍下出现的问题：

- 修改了producer的代码后需要重启worker才能生效，这个不知道新版本改善否
- 调用ansible的时候woker必须添加环境变量export PYTHONOPTIMIZE=1或者woker启动的时候添加参数-O OPTIMIZATION



---

参考网址：

<http://docs.jinkan.org/docs/celery/> （刚入门，还是推荐看中文版，虽然当前是4.3了，但是项目是3.1，所以继续使用）

<https://zhuanlan.zhihu.com/p/43588348> （初级使用文档）